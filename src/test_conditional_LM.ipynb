{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import utils_testing\n",
    "import utils\n",
    "from utils import str2bool\n",
    "import colorama\n",
    "import re\n",
    "import sys\n",
    "from gpt2_model.tokenization_gpt2 import GPT2Tokenizer\n",
    "from gpt2_model.modeling_gpt2_condition import GPT2LMHeadModel\n",
    "from gpt2_model.configuration_gpt2 import GPT2Config\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Interactive LM')\n",
    "#path\n",
    "parser.add_argument('--checkpoint_topics', type=str, default='../models/',\n",
    "                    help='topical model checkpoint to use')\n",
    "parser.add_argument('--checkpoint_conditional', type=str, default='../models/',\n",
    "                    help='conditional LM model checkpoint to use')\n",
    "parser.add_argument('--emb_file', type=str, default='target_emb.pt',\n",
    "                    help='path to a word embedding file')\n",
    "parser.add_argument('--word_dict', type=str, default='../data/processed/wiki2016_gpt2/tensors_all_min100/dict_idx_compact',\n",
    "                    help='path to a dictionary file')\n",
    "#parser.add_argument('--outf', type=str, default='../gen_log/generated.txt',\n",
    "#                    help='output file for generated text')\n",
    "\n",
    "#parser.add_argument('--batch_size', type=int, default=3, metavar='N',\n",
    "#                    help='batch size')\n",
    "parser.add_argument('--num_sent_gen', type=int, default=3, metavar='N',\n",
    "                    help='In each prompt, generate how many sentences')\n",
    "parser.add_argument('--gen_sent_len', type=int, default=50, metavar='N',\n",
    "                    help='In each prompt, generate sentences with length gen_sent_len')\n",
    "parser.add_argument('--bptt', type=int, default=512,\n",
    "                    help='sequence length')\n",
    "parser.add_argument('--bptt_conditional', type=int, default=256,\n",
    "                    help='sequence length')\n",
    "parser.add_argument('--top_k_nn', type=int, default=5,\n",
    "                    help='Representing each topic using how many words')\n",
    "\n",
    "parser.add_argument('--cuda_topics', type=str2bool, nargs='?', default=True,\n",
    "                    help='use CUDA for topical model')\n",
    "parser.add_argument('--cuda_conditional', type=str2bool, nargs='?', default=True,\n",
    "                    help='use CUDA for conditional LM')\n",
    "parser.add_argument('--single_gpu', default=True, action='store_true',\n",
    "                    help='use single GPU')\n",
    "\n",
    "utils_testing.add_model_arguments(parser)\n",
    "\n",
    "args = parser.parse_args(\"\"\"--checkpoint_topics ../models/future_topic_all-20200106-222318\n",
    "                         --checkpoint_conditional ../models/conditional_all-20200106-235956\n",
    "                         --word_dict ../data/processed/wiki2016_gpt2/tensors_all_min100/dict_idx_compact\"\"\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_future): Linear(in_features=300, out_features=768, bias=True)\n",
       "    (wpe_future): Embedding(1024, 768)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.emb_file == \"target_emb.pt\":\n",
    "    args.emb_file =  os.path.join(args.checkpoint_topics,\"target_emb.pt\")\n",
    "device_topics = torch.device(\"cuda:0\" if args.cuda_topics else \"cpu\")\n",
    "device_conditional = torch.device(\"cuda:1\" if args.cuda_conditional else \"cpu\")\n",
    "with open(args.word_dict) as f_in:\n",
    "    idx2word_freq = utils.load_idx2word_freq(f_in)\n",
    "word_d2_idx = {}\n",
    "for i in range(len(idx2word_freq)):\n",
    "    w, freq = idx2word_freq[i]\n",
    "    word_d2_idx[w] = i\n",
    "\n",
    "parallel_encoder, parallel_decoder, encoder, decoder, word_norm_emb = utils.loading_all_models(args, idx2word_freq, device_topics)\n",
    "output_emb_size = word_norm_emb.size(1)\n",
    "print(next(encoder.parameters()).device)\n",
    "\n",
    "model_name = 'gpt2'\n",
    "\n",
    "encoder_state_dict = torch.load(os.path.join(args.checkpoint_conditional, 'encoder.pt'), map_location=device_conditional)\n",
    "gpt2_config = GPT2Config.from_pretrained(model_name)\n",
    "gpt2_config.word_emb_dim = output_emb_size\n",
    "model_condition = GPT2LMHeadModel.from_pretrained(model_name, state_dict = encoder_state_dict, config = gpt2_config).cuda(device_conditional)\n",
    "print(next(model_condition.parameters()).device)\n",
    "\n",
    "tokenizer_GPT2 = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "model_condition.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_future_topics(prompt, encoder, decoder, word_norm_emb, n_basis, top_k, bptt, idx2word_freq, tokenizer_GPT2, device_topics):\n",
    "    tokenized_text = tokenizer_GPT2.tokenize(prompt, add_prefix_space=True)\n",
    "    indexed_tokens = tokenizer_GPT2.convert_tokens_to_ids(tokenized_text)\n",
    "    start_idx = len(indexed_tokens) - bptt\n",
    "    if start_idx > 0:\n",
    "        indexed_tokens = indexed_tokens[start_idx:]\n",
    "    feature = torch.tensor(indexed_tokens, dtype=torch.long, device=device_topics).unsqueeze(0)\n",
    "    output_emb, past = parallel_encoder(feature)\n",
    "    output_emb_last = output_emb[:,-1,:]\n",
    "    basis_pred = decoder(output_emb_last)\n",
    "    basis_norm_pred = basis_pred / (0.000000000001 + basis_pred.norm(dim = 2, keepdim=True) )\n",
    "    \n",
    "    basis_norm_pred = basis_norm_pred.permute(0,2,1)\n",
    "    sim_pairwise = torch.matmul(word_norm_emb.unsqueeze(dim = 0), basis_norm_pred)\n",
    "    top_value, top_index = torch.topk(sim_pairwise, top_k, dim = 1, sorted=True)\n",
    "    top_value = top_value / (0.000000000001 + top_value.sum(dim = 1, keepdim=True) )\n",
    "    #out_str = ''\n",
    "    for j in range(n_basis):\n",
    "        out_str = str(j) + ', '\n",
    "        for k in range(top_k):\n",
    "            word_nn = idx2word_freq[top_index[0,k,j].item()][0]\n",
    "            out_str += word_nn+' {:5.3f} '.format(top_value[0,k,j].item()) \n",
    "        print(out_str)\n",
    "    print()\n",
    "            \n",
    "    return top_value, top_index, feature\n",
    "\n",
    "def conditional_generation(selected_conditions, gen_sent_len, num_sent_gen, word_d2_idx, idx2word_freq, model_condition, word_norm_emb, top_index, top_value, feature, bptt_conditional, tokenizer_GPT2, device_conditional):\n",
    "    word_norm_emb_top = word_norm_emb[top_index,:]\n",
    "    word_norm_emb_w_sum = torch.sum( word_norm_emb_top * top_value.unsqueeze(-1), dim = 1) / top_value.unsqueeze(-1).sum(dim = 1)\n",
    "    word_w_sum_norm = word_norm_emb_w_sum / (0.000000000001 + word_norm_emb_w_sum.norm(dim = -1, keepdim=True))\n",
    "    word_w_sum_norm = word_w_sum_norm.to(device=device_conditional)\n",
    "    selected_topic_idx = []\n",
    "    selected_word_idx = []\n",
    "    for x in selected_conditions:\n",
    "        if isinstance(x, int):\n",
    "            selected_topic_idx.append(x)\n",
    "        else:\n",
    "            if x not in word_d2_idx:\n",
    "                print('Warning: Ignore the word '+x+' because it is too rare')\n",
    "                continue\n",
    "            selected_word_idx.append(word_d2_idx[x])\n",
    "    selected_topic_idx = torch.tensor(np.sort(selected_topic_idx), dtype=torch.long, device = device_conditional)\n",
    "    selected_word_idx = torch.tensor(selected_word_idx, dtype=torch.long, device = device_conditional)\n",
    "    \n",
    "    end_int = feature.size(1)\n",
    "    max_prompt_len = bptt_conditional - gen_sent_len\n",
    "    start_int = 0\n",
    "    if end_int > max_prompt_len:\n",
    "        start_int = end_int - max_prompt_len\n",
    "    insert_loc_list = []\n",
    "    insert_loc_list.append(end_int - 1)\n",
    "    insert_loc_truncated = np.array(insert_loc_list) - start_int\n",
    "    \n",
    "    feature_expanded = feature[0,start_int:end_int].unsqueeze(0).expand(num_sent_gen,end_int - start_int).to(device = device_conditional)\n",
    "    future_emb_chosen_topics = word_w_sum_norm[0, selected_topic_idx,:]\n",
    "    future_emb_chosen_words = word_norm_emb[selected_word_idx,:]\n",
    "    num_selection = future_emb_chosen_topics.size(0) + future_emb_chosen_words.size(0)\n",
    "    future_emb_chosen = torch.cat([future_emb_chosen_topics, future_emb_chosen_words],dim=0).unsqueeze(0).expand(num_sent_gen,num_selection,word_norm_emb.size(-1))\n",
    "    future_emb_chosen_arr = []\n",
    "    future_emb_chosen_arr.append(future_emb_chosen)\n",
    "    truncate_idx = 0\n",
    "    output = utils_testing.sample_seq(model_condition, feature_expanded, insert_loc_truncated[truncate_idx:], future_emb_chosen_arr[truncate_idx:], gen_sent_len, device_conditional)\n",
    "    output_org = utils_testing.sample_seq(model_condition, feature_expanded, None, None, gen_sent_len, device_conditional)\n",
    "    for j in range(num_sent_gen):\n",
    "        generated_sent = tokenizer_GPT2.convert_tokens_to_string( [tokenizer_GPT2._convert_id_to_token(x) for x in output[j, :].tolist()] )\n",
    "        utils_testing.print_sampled_sent(selected_topic_idx.tolist(), generated_sent, top_index[0,:,:], idx2word_freq, sys.stdout, 'conditional '+ str(j), selected_word_idx.tolist())\n",
    "    for j in range(num_sent_gen):\n",
    "        generated_sent_org = tokenizer_GPT2.convert_tokens_to_string( [tokenizer_GPT2._convert_id_to_token(x) for x in output_org[j, :].tolist()] )\n",
    "        utils_testing.print_sampled_sent(selected_topic_idx.tolist(), generated_sent_org, top_index[0,:,:], idx2word_freq, sys.stdout, 'original '+ str(j), selected_word_idx.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, Obama 0.205 McCain 0.203 GOP 0.198 Republicans 0.198 conservatives 0.197 \n",
      "1, Committee 0.224 Legislative 0.203 Representatives 0.194 Council 0.190 Subcommittee 0.189 \n",
      "2, Party 0.237 party 0.226 parties 0.189 Parties 0.187 PARTY 0.161 \n",
      "3, Dennis 0.201 Larry 0.201 Allen 0.200 Thompson 0.199 Miller 0.199 \n",
      "4, government 0.221 federal 0.219 governmental 0.194 enforcement 0.186 finance 0.181 \n",
      "5, 2009 0.206 2008 0.204 2010 0.201 2007 0.199 2011 0.190 \n",
      "6, resigned 0.205 insisted 0.201 agreed 0.200 president 0.198 refused 0.197 \n",
      "7, Clintons 0.204 conservatives 0.202 Gingrich 0.199 Santorum 0.199 McCain 0.197 \n",
      "8, election 0.218 elections 0.203 voters 0.196 voting 0.192 vote 0.191 \n",
      "9, Ohio 0.205 Pennsylvania 0.204 States 0.200 Maryland 0.197 Illinois 0.194 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#prompt = \"The magician curses the zombie\"\n",
    "prompt = \"Trump, the leader of the Republican\"\n",
    "top_value, top_index, feature = show_future_topics(prompt, parallel_encoder, parallel_decoder, word_norm_emb, args.n_basis, args.top_k_nn, args.bptt, idx2word_freq, tokenizer_GPT2, device_topics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional 0:  ticket, was unopposed, and carried the district by a slim margin. He ran on the Republican ticket for the U.S. Senate and served as Chairman of the House Republican Committee. In the Republican primary, he defeated incumbent Governor Edward R. Murrow of Ohio by 5,000 \u001b[31mvote\u001b[0ms, defeating Democrat Frank Ross of New York. In the Republican primary, he defeated Republican opponent Paul A. Young and re-appeared on the Republican ticket unopposed. In the Republican primary,\n",
      "8 topic: {'vote': 1}\n",
      "\n",
      "conditional 1:  \u001b[31mParty\u001b[0m, described him as a  tough-minded man with a lot of experience and confidence. His opponent, Democrat Dan Conzembe, said he planned to make a major upset in the Republican primary to win the 2016 presidential \u001b[31melection\u001b[0m. The \u001b[31melection\u001b[0m of 2016 will not take place on a national, non-partisan basis and will instead be on a \u001b[31mparty\u001b[0m-list proportional representation list (PLP). In December 2014,        A number of members of the \u001b[31mparty\u001b[0m announced their\n",
      "2 topic: {'Party': 1, 'party': 2}\n",
      "8 topic: {'election': 2}\n",
      "\n",
      "conditional 2:  presidential nominee John \u001b[31mMcCain\u001b[0m, and his running mate Mitt Romney were the leading contenders for the Republican nomination. In a January 8, 2011 poll from the Democratic \u001b[31mParty\u001b[0m, \u001b[31mMcCain\u001b[0m defeated Democratic challenger Gary Dobson of Virginia over Coburn, by a margin of 8,904 \u001b[31mvote\u001b[0ms, to win the race for the Republican nomination, despite Dobson's victory in the Democratic landslide. Dobson won the seat with a margin of 23,974 \u001b[31mvote\u001b[0ms. In November 2010, \u001b[31mMcCain\u001b[0m received 4,814 \u001b[31mvote\u001b[0ms\n",
      "0 topic: {'McCain': 3}\n",
      "2 topic: {'Party': 1}\n",
      "8 topic: {'vote': 3}\n",
      "\n",
      "original 0:  \u001b[31mparty\u001b[0m, has not returned to the House of Representatives,  and will not take the seat vacated by Democrat Matt Smith. On May 21, 2010, a week-long special \u001b[31melection\u001b[0m was held within the week prior to the Republican primary. Two candidates filed to challenge their respective seats; Perry, a businessman, and former Massachusetts governor and former Republican Governor Mitt Romney, a former chairman of the Bain Capital Management Board of Advisors. Both candidates ran without opposition. Perry's platform included a federal deficit reduction bill\n",
      "2 topic: {'party': 1}\n",
      "8 topic: {'election': 1}\n",
      "\n",
      "original 1:  \u001b[31mParty\u001b[0m in Florida, called for a constitutional review of presidential powers and a constitutional amendment to abolish the Supreme Court in a Constitutional Court case     in which the Supreme Court would be abolished. The plan was rejected. At that time, the Senate said it would not accept either and that it would consider the constitutionality of the bill but would not consider whether to change the Supreme Court. The Senate rejected both, saying it would  consider the constitutional validity of the Constitution . The Senate then passed an\n",
      "2 topic: {'Party': 1}\n",
      "\n",
      "original 2:  \u001b[31mParty\u001b[0m in North Carolina, endorsed Walker. Walker won the General Election with 59% of the first \u001b[31mvote\u001b[0m and finished second in a field of 15 candidates. Walker defeated the Republican candidate Don King, an African-American Democrat serving on the North Carolina State Senate for several years before he was released from service. Other candidates supporting Walker include Tom Hildebrand, a Democrat who is a state senator, and Peter Hildebrand, another Democrat who served as lieutenant governor in the South Carolina Senate, and who later\n",
      "2 topic: {'Party': 1}\n",
      "8 topic: {'vote': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_conditions = [0,8,2]\n",
    "#gen_sent_len = args.gen_sent_len\n",
    "gen_sent_len = 100\n",
    "num_sent_gen = args.num_sent_gen\n",
    "conditional_generation(selected_conditions, gen_sent_len, num_sent_gen, word_d2_idx, idx2word_freq, model_condition, word_norm_emb, top_index, top_value, feature, args.bptt_conditional, tokenizer_GPT2, device_conditional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
