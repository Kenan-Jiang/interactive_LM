{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import utils_testing\n",
    "import utils\n",
    "from utils import str2bool\n",
    "import colorama\n",
    "import re\n",
    "import sys\n",
    "from gpt2_model.tokenization_gpt2 import GPT2Tokenizer\n",
    "from gpt2_model.modeling_gpt2_condition import GPT2LMHeadModel\n",
    "from gpt2_model.configuration_gpt2 import GPT2Config\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Interactive LM')\n",
    "#path\n",
    "parser.add_argument('--checkpoint_topics', type=str, default='../models/',\n",
    "                    help='topical model checkpoint to use')\n",
    "parser.add_argument('--checkpoint_conditional', type=str, default='../models/',\n",
    "                    help='conditional LM model checkpoint to use')\n",
    "parser.add_argument('--emb_file', type=str, default='target_emb.pt',\n",
    "                    help='path to a word embedding file')\n",
    "parser.add_argument('--word_dict', type=str, default='../data/processed/wiki2016_gpt2/tensors_all_min100/dict_idx_compact',\n",
    "                    help='path to a dictionary file')\n",
    "#parser.add_argument('--outf', type=str, default='../gen_log/generated.txt',\n",
    "#                    help='output file for generated text')\n",
    "\n",
    "#parser.add_argument('--batch_size', type=int, default=3, metavar='N',\n",
    "#                    help='batch size')\n",
    "parser.add_argument('--num_sent_gen', type=int, default=3, metavar='N',\n",
    "                    help='In each prompt, generate how many sentences')\n",
    "parser.add_argument('--gen_sent_len', type=int, default=50, metavar='N',\n",
    "                    help='In each prompt, generate sentences with length gen_sent_len')\n",
    "parser.add_argument('--bptt', type=int, default=512,\n",
    "                    help='sequence length')\n",
    "parser.add_argument('--bptt_conditional', type=int, default=256,\n",
    "                    help='sequence length')\n",
    "parser.add_argument('--top_k_nn', type=int, default=5,\n",
    "                    help='Representing each topic using how many words')\n",
    "\n",
    "parser.add_argument('--cuda_topics', type=str2bool, nargs='?', default=True,\n",
    "                    help='use CUDA for topical model')\n",
    "parser.add_argument('--cuda_conditional', type=str2bool, nargs='?', default=True,\n",
    "                    help='use CUDA for conditional LM')\n",
    "parser.add_argument('--single_gpu', default=True, action='store_true',\n",
    "                    help='use single GPU')\n",
    "\n",
    "utils_testing.add_model_arguments(parser)\n",
    "\n",
    "args = parser.parse_args(\"\"\"--checkpoint_topics ../models/future_topic_all-20200106-222318\n",
    "                         --checkpoint_conditional ../models/conditional_all-20200106-235956\n",
    "                         --word_dict ../data/processed/wiki2016_gpt2/tensors_all_min100/dict_idx_compact\"\"\".split())\n",
    "\n",
    "#new average model\n",
    "args = parser.parse_args(\"\"\"--checkpoint_topics ../models/future_topic_all-20200106-222318\n",
    "                         --checkpoint_conditional ../models/conditional_all-20200115-160129\n",
    "                         --word_dict ../data/processed/wiki2016_gpt2/tensors_all_min100/dict_idx_compact\"\"\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_future): Linear(in_features=300, out_features=768, bias=True)\n",
       "    (wpe_future): Embedding(1024, 768)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.emb_file == \"target_emb.pt\":\n",
    "    args.emb_file =  os.path.join(args.checkpoint_topics,\"target_emb.pt\")\n",
    "device_topics = torch.device(\"cuda:0\" if args.cuda_topics else \"cpu\")\n",
    "device_conditional = torch.device(\"cuda:1\" if args.cuda_conditional else \"cpu\")\n",
    "with open(args.word_dict) as f_in:\n",
    "    idx2word_freq = utils.load_idx2word_freq(f_in)\n",
    "word_d2_idx = {}\n",
    "for i in range(len(idx2word_freq)):\n",
    "    w, freq = idx2word_freq[i]\n",
    "    word_d2_idx[w] = i\n",
    "\n",
    "parallel_encoder, parallel_decoder, encoder, decoder, word_norm_emb = utils.loading_all_models(args, idx2word_freq, device_topics)\n",
    "output_emb_size = word_norm_emb.size(1)\n",
    "#print(next(encoder.parameters()).device)\n",
    "\n",
    "model_name = 'gpt2'\n",
    "\n",
    "encoder_state_dict = torch.load(os.path.join(args.checkpoint_conditional, 'encoder.pt'), map_location=device_conditional)\n",
    "gpt2_config = GPT2Config.from_pretrained(model_name)\n",
    "gpt2_config.word_emb_dim = output_emb_size\n",
    "model_condition = GPT2LMHeadModel.from_pretrained(model_name, state_dict = encoder_state_dict, config = gpt2_config).cuda(device_conditional)\n",
    "#print(next(model_condition.parameters()).device)\n",
    "\n",
    "tokenizer_GPT2 = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "model_condition.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_future_topics(prompt, encoder, decoder, word_norm_emb, n_basis, top_k, bptt, idx2word_freq, tokenizer_GPT2, device_topics):\n",
    "    tokenized_text = tokenizer_GPT2.tokenize(prompt, add_prefix_space=True)\n",
    "    indexed_tokens = tokenizer_GPT2.convert_tokens_to_ids(tokenized_text)\n",
    "    start_idx = len(indexed_tokens) - bptt\n",
    "    if start_idx > 0:\n",
    "        indexed_tokens = indexed_tokens[start_idx:]\n",
    "    feature = torch.tensor(indexed_tokens, dtype=torch.long, device=device_topics).unsqueeze(0)\n",
    "    output_emb, past = parallel_encoder(feature)\n",
    "    output_emb_last = output_emb[:,-1,:]\n",
    "    basis_pred = decoder(output_emb_last)\n",
    "    basis_norm_pred = basis_pred / (0.000000000001 + basis_pred.norm(dim = 2, keepdim=True) )\n",
    "    \n",
    "    basis_norm_pred = basis_norm_pred.permute(0,2,1)\n",
    "    sim_pairwise = torch.matmul(word_norm_emb.unsqueeze(dim = 0), basis_norm_pred)\n",
    "    top_value, top_index = torch.topk(sim_pairwise, top_k, dim = 1, sorted=True)\n",
    "    top_value = top_value / (0.000000000001 + top_value.sum(dim = 1, keepdim=True) )\n",
    "    #out_str = ''\n",
    "    for j in range(n_basis):\n",
    "        out_str = str(j) + ', '\n",
    "        for k in range(top_k):\n",
    "            word_nn = idx2word_freq[top_index[0,k,j].item()][0]\n",
    "            out_str += word_nn+' {:5.3f} '.format(top_value[0,k,j].item()) \n",
    "        print(out_str)\n",
    "    print()\n",
    "            \n",
    "    return top_value, top_index, feature\n",
    "\n",
    "def conditional_generation(selected_conditions, gen_sent_len, num_sent_gen, word_d2_idx, idx2word_freq, model_condition, word_norm_emb, top_index, top_value, feature, bptt_conditional, tokenizer_GPT2, device_conditional):\n",
    "    word_norm_emb_top = word_norm_emb[top_index,:]\n",
    "    word_norm_emb_w_sum = torch.sum( word_norm_emb_top * top_value.unsqueeze(-1), dim = 1) / top_value.unsqueeze(-1).sum(dim = 1)\n",
    "    word_w_sum_norm = word_norm_emb_w_sum / (0.000000000001 + word_norm_emb_w_sum.norm(dim = -1, keepdim=True))\n",
    "    word_w_sum_norm = word_w_sum_norm.to(device=device_conditional)\n",
    "    selected_topic_idx = []\n",
    "    selected_word_idx = []\n",
    "    for x in selected_conditions:\n",
    "        if isinstance(x, int):\n",
    "            selected_topic_idx.append(x)\n",
    "        else:\n",
    "            if x not in word_d2_idx:\n",
    "                print('Warning: Ignore the word '+x+' because it is too rare')\n",
    "                continue\n",
    "            selected_word_idx.append(word_d2_idx[x])\n",
    "    selected_topic_idx = torch.tensor(np.sort(selected_topic_idx), dtype=torch.long, device = device_conditional)\n",
    "    selected_word_idx = torch.tensor(selected_word_idx, dtype=torch.long, device = device_conditional)\n",
    "    \n",
    "    end_int = feature.size(1)\n",
    "    max_prompt_len = bptt_conditional - gen_sent_len\n",
    "    start_int = 0\n",
    "    if end_int > max_prompt_len:\n",
    "        start_int = end_int - max_prompt_len\n",
    "    insert_loc_list = []\n",
    "    insert_loc_list.append(end_int - 1)\n",
    "    insert_loc_truncated = np.array(insert_loc_list) - start_int\n",
    "    \n",
    "    feature_expanded = feature[0,start_int:end_int].unsqueeze(0).expand(num_sent_gen,end_int - start_int).to(device = device_conditional)\n",
    "    future_emb_chosen_topics = word_w_sum_norm[0, selected_topic_idx,:]\n",
    "    future_emb_chosen_words = word_norm_emb[selected_word_idx,:]\n",
    "    num_selection = future_emb_chosen_topics.size(0) + future_emb_chosen_words.size(0)\n",
    "    future_emb_chosen = torch.cat([future_emb_chosen_topics, future_emb_chosen_words],dim=0).unsqueeze(0).expand(num_sent_gen,num_selection,word_norm_emb.size(-1))\n",
    "    future_emb_chosen_arr = []\n",
    "    future_emb_chosen_arr.append(future_emb_chosen)\n",
    "    truncate_idx = 0\n",
    "    output = utils_testing.sample_seq(model_condition, feature_expanded, insert_loc_truncated[truncate_idx:], future_emb_chosen_arr[truncate_idx:], gen_sent_len, device_conditional)\n",
    "    output_org = utils_testing.sample_seq(model_condition, feature_expanded, None, None, gen_sent_len, device_conditional)\n",
    "    for j in range(num_sent_gen):\n",
    "        generated_sent = tokenizer_GPT2.convert_tokens_to_string( [tokenizer_GPT2._convert_id_to_token(x) for x in output[j, :].tolist()] )\n",
    "        utils_testing.print_sampled_sent(selected_topic_idx.tolist(), generated_sent, top_index[0,:,:], idx2word_freq, sys.stdout, 'conditional '+ str(j), selected_word_idx.tolist())\n",
    "    for j in range(num_sent_gen):\n",
    "        generated_sent_org = tokenizer_GPT2.convert_tokens_to_string( [tokenizer_GPT2._convert_id_to_token(x) for x in output_org[j, :].tolist()] )\n",
    "        utils_testing.print_sampled_sent(selected_topic_idx.tolist(), generated_sent_org, top_index[0,:,:], idx2word_freq, sys.stdout, 'original '+ str(j), selected_word_idx.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, tale 0.215 fictional 0.203 characters 0.200 storyline 0.192 story 0.189 \n",
      "1, underneath 0.211 red 0.200 pink 0.198 neck 0.196 legs 0.195 \n",
      "2, gods 0.210 deity 0.209 deities 0.194 kingdom 0.194 lord 0.193 \n",
      "3, Mikey 0.208 sidekick 0.205 Mickey 0.202 Archie 0.194 Timmy 0.191 \n",
      "4, boy 0.207 girl 0.207 bunny 0.200 kitty 0.194 lady 0.193 \n",
      "5, takes 0.203 discovers 0.200 pushes 0.200 informs 0.199 puts 0.199 \n",
      "6, want 0.204 sure 0.203 way 0.199 know 0.198 even 0.196 \n",
      "7, fearful 0.209 oblivious 0.202 malevolent 0.197 disdain 0.196 resentful 0.195 \n",
      "8, killed 0.210 killing 0.209 kill 0.197 attack 0.193 deadly 0.191 \n",
      "9, Demon 0.216 Undead 0.202 Werewolf 0.196 Goblin 0.194 Curse 0.193 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#prompt = \"Barack Obama writes a new book\"\n",
    "#prompt = \"Barack Obama writes a new book on spirituality and the role of religion in society\"\n",
    "prompt = \"The magician curses the zombie\"\n",
    "#with torch.no_grad():\n",
    "#    top_value, top_index, feature = show_future_topics(prompt, parallel_encoder, parallel_decoder, word_norm_emb, args.n_basis, args.top_k_nn, args.bptt, idx2word_freq, tokenizer_GPT2, device_topics)\n",
    "prompt = \"Trump, the leader of the Republican\"\n",
    "top_value, top_index, feature = show_future_topics(prompt, parallel_encoder, parallel_decoder, word_norm_emb, args.n_basis, args.top_k_nn, args.bptt, idx2word_freq, tokenizer_GPT2, device_topics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional 0:  and asks their help. He says they were all created by demons, and the godmother explains that the demons were aware of the magic they created. He asks if there is evil in this world, as well as how their \u001b[31mlord\u001b[0m (and only a benign \u001b[31mboy\u001b[0m and \u001b[31mgirl\u001b[0m) are all  \u001b[31mhappy\u001b[0m to live . That night they meet a young \u001b[31mboy\u001b[0m with a demonic face from a man in the shadow who looks almost as if he will be reborn, and he reveals the real identity of the demon to the\n",
      "2 topic: {'lord': 1}\n",
      "4 topic: {'boy': 2, 'girl': 1}\n",
      "word: {'happy': 1}\n",
      "\n",
      "conditional 1:  with a stick of soap (which contains no soap), and he fears that there might be an undead doll in the house. As the spirit walks on, the demon appears, and is not \u001b[31mhappy\u001b[0m with him. The demon and its \u001b[31mdeities\u001b[0m alike are \u001b[31moblivious\u001b[0m to the presence of the undead, and wish that their \u001b[31mgods\u001b[0m would have them restored after all. The demon returns to the house by means of a pair of rope straps, allowing them to escape. The demon appears again, and the demon and the goddess\n",
      "2 topic: {'gods': 1, 'deities': 1}\n",
      "7 topic: {'oblivious': 1}\n",
      "word: {'happy': 1}\n",
      "\n",
      "conditional 2:  demon with the name of the demon to protect the world. The monster is \u001b[31mfearful\u001b[0m of death, so they are scared into living a \u001b[31mhappy\u001b[0m life. However, the villain is \u001b[31moblivious\u001b[0m to that, and decides to get the demon out of life. To get him out, he asks a \u001b[31mgirl\u001b[0m-chick who lives with him to help her escape, not only by using magic but also by giving her some drugs which he can use to kill the monster and help the demon. When he catches the demon,\n",
      "4 topic: {'girl': 1}\n",
      "7 topic: {'fearful': 1, 'oblivious': 1}\n",
      "word: {'happy': 1}\n",
      "\n",
      "original 0:  and then the    zombie shows him and his friends a sign that says  M  appears. This appears on the door of the zombies' house. As the zombie starts to appear to enter the cellar, M is shot in the back by a person he has known for months. His last name appears as  W  in the box, then  A  in the bag in the corner, and finally  C  in the bag in front of the zombie. Then is the entrance to\n",
      "\n",
      "original 1:  with a spell and his magic strikes them both with his lightning force. In one scene in The Living Daylights, he makes another attempt to spell his spell (this time at the side of an old witch, and the only one who is able to do so) but the witch hits him with her magic again; he finally escapes with a kiss. In a cameo in the episode  Deadliest Night , the demon is seen making a deal with the Wicked Witch of the West, that when she uses\n",
      "\n",
      "original 2:  with a series of words,  I know I can't play,  which she eventually does with a moustache and mouth. After the end credits, Molly awakens at a hospital. The zombie, Molly's spirit, is then attacked by  a demon with a demon's mouth. The demon removes Molly's face and the demon tries to escape. The demon attacks Molly again when she touches the demon's mouth by hitting one on his head with a shovel. Molly rushes in and defeats the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_conditions = [4,7,2,'happy'] #[4,8,2,'happy'] #['zombie'] #[2] #['zombie'] #[4,8,2,'happy']\n",
    "#selected_conditions = [6]\n",
    "gen_sent_len = args.gen_sent_len\n",
    "#gen_sent_len = 100\n",
    "num_sent_gen = args.num_sent_gen\n",
    "conditional_generation(selected_conditions, gen_sent_len, num_sent_gen, word_d2_idx, idx2word_freq, model_condition, word_norm_emb, top_index, top_value, feature, args.bptt_conditional, tokenizer_GPT2, device_conditional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
